<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>cognitive-sciences on</title><link>https://jzhao.xyz/tags/cognitive-sciences/</link><description>Recent content in cognitive-sciences on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 13 Jul 2021 18:17:48 -0400</lastBuildDate><atom:link href="https://jzhao.xyz/tags/cognitive-sciences/index.xml" rel="self" type="application/rss+xml"/><item><title>Multiple Realization</title><link>https://jzhao.xyz/thoughts/multiple-realization/</link><pubDate>Tue, 13 Jul 2021 18:17:48 -0400</pubDate><guid>https://jzhao.xyz/thoughts/multiple-realization/</guid><description>Are there multiple ways of realizing intelligence?
the bitter lesson → http://www.incompleteideas.net/IncIdeas/BitterLesson.html
a bitter lesson reframing data? speech data → audio features / mfcc inadvertently taking away the ability to make new insights based of restrictions how do we explore more of the solution space feedforward → linear relationships sigmoid → non-linear what other solution spaces are we missing do we necessarily need human intelligence for machine intelligence?</description></item><item><title>Life Definition</title><link>https://jzhao.xyz/thoughts/life-definition/</link><pubDate>Fri, 02 Jul 2021 21:38:52 -0400</pubDate><guid>https://jzhao.xyz/thoughts/life-definition/</guid><description>Matthews Ozma of oz Tik-Tok → &amp;ldquo;Thinks, Speaks, Acts, and Does Everything but Live&amp;rdquo; Tin Man vs Tik-Tok Tin Man used to be living (born a real man) but lost his body over time due to a series of wood chopping &amp;lsquo;accidents&amp;rsquo; a modern tale of the ship of Theseus does the original entity persist through the gradual replacement of each of its parts, if it doesn&amp;rsquo;t, where does it stop being the same entity?</description></item><item><title>Telerobotics</title><link>https://jzhao.xyz/thoughts/telerobotics/</link><pubDate>Fri, 02 Jul 2021 21:37:23 -0400</pubDate><guid>https://jzhao.xyz/thoughts/telerobotics/</guid><description>Clark &amp;ldquo;distance is what there is no action at&amp;rdquo; draw the lines of proximity and distance according to the criterion of effective action Dennett&amp;rsquo;s 1981 &amp;ldquo;where am I&amp;rdquo; story secret experiment, Dennett&amp;rsquo;s brain is remove, kept alive in a tank of nutrients, and equipped with a multitude of radio links by means of which it executes all of its normal bodily control functions Dennet&amp;rsquo;s body is then equipped with receivers and transmitters so that it can use its built-in sensors (eyes, ears, etc.</description></item><item><title>Virtual Worlds</title><link>https://jzhao.xyz/thoughts/virtual-worlds/</link><pubDate>Fri, 02 Jul 2021 16:23:05 -0400</pubDate><guid>https://jzhao.xyz/thoughts/virtual-worlds/</guid><description>Personal Thoughts Bridging the real and the virtual moving away from personal computing started off with timeshare personal computing now streaming EVERYTHING to the cloud devices will just be viewing places https://www.mightyapp.com/ No matter how hard we try, our virtual selves will inevitably be tethered to our physical selves. Interface with these virtual worlds through looking at our screens, typing on our keyboards, etc. even with a pseudonymous-web that is not supposedly tied to anything in the physical realm.</description></item><item><title>Mind-Body Problem</title><link>https://jzhao.xyz/thoughts/mind-body-problem/</link><pubDate>Fri, 02 Jul 2021 15:43:59 -0400</pubDate><guid>https://jzhao.xyz/thoughts/mind-body-problem/</guid><description>Crane understanding the brain may be the best path to understanding minds The mind-body problem how the mind and body are connected to one another are we just entirely made up of matter or is there something more? two points of doubt we know a bit about minds without knowing anything about brains are minds different from brains not true, they still might be the same thing materialism (physicalism) → minds and brains are identical (identity theory) nothing magical about minds, just the brains activity dualism → minds are distinct from the brain idealism → everything is mental/in the mind considering other minds for own mind → introspection works, more or less for other minds → must rely on behaviour of others (what they say and do) two possible ways of understanding how this way of knowing other minds works behaviourism → behaviour is all there is to mentality seems inconsistent w introspection we have thoughts that are never reflected in our behaviour can have multiple thoughts that correspond with a behaviour → umbrella example a man looks out of a window, goes to a closet and takes an umbrella before leaving his house what is he thinking?</description></item><item><title>Language of Thought</title><link>https://jzhao.xyz/thoughts/language-of-thought/</link><pubDate>Fri, 02 Jul 2021 15:40:00 -0400</pubDate><guid>https://jzhao.xyz/thoughts/language-of-thought/</guid><description>Can we use language as the method of querying memory?
Crane Language of thought hypothesis → LOTH proposes thinking occurs in a mental language, this is called mentalese computations in a classical way classical computational architecture distinguishes between data-structures and rules/programs which operate on said structures sequential processing rather than parallel &amp;lsquo;rules and representations picture&amp;rsquo; sometimes called GOFAI neural networks or connectionist computational models challenges any argument for mentalese architecture large number of units which are connected to others (connectionism) and the connections have different strengths (weights) units are arranged in layers computation happens in parallel like in a classical machine, representations are assigned to connectionist networks by the people who build them two types of connectionist representation localist → each unit is assigned a feature as a whole that represents distributed → state of the network as a whole represents something often claimed to be one of the distinctive features of connectionism connectionist networks is sometimes called parallel distributed processing (PDP) can be trained to learn resemble the structure of the brain much more closely than any classical computer really good at pattern recognition Putnam Turing Test dialogic test of competence exploring the notion of reference are the things the machine refers to the same things we refer to?</description></item><item><title>Representation</title><link>https://jzhao.xyz/thoughts/representation/</link><pubDate>Fri, 02 Jul 2021 15:33:29 -0400</pubDate><guid>https://jzhao.xyz/thoughts/representation/</guid><description>Crane Symbolic Representation mans just kinda doesn&amp;rsquo;t agree w/ the pioneer 10 space probe plate lmao symbols will not mean anything to any alien life we find it easy to understand because we have the context and we live on this planet words do not have meaning in and of themselves (no intrinsic meaning) what sort of things can be representations words/pictures/numbers/diagrams state of mind, can represent almost anything at all what sort of things can be objects of representations almost anything (physical objects, sentences, numbers, moods, feelings, emotions, non-existent things) pictures represent by resemblance → derivative intention ‘resemblance theory of pictorial representation’, or the &amp;lsquo;resemblance theory&amp;rsquo; WC ant argument, resemblance is not enough for reference X represents Y → suggests that representation is a relation between two things is there a basic type of representation underlying everything else?</description></item><item><title>Mind Design</title><link>https://jzhao.xyz/thoughts/mind-design/</link><pubDate>Fri, 02 Jul 2021 15:27:30 -0400</pubDate><guid>https://jzhao.xyz/thoughts/mind-design/</guid><description>Haugeland 1 → what is mind design? understand the mind in terms of its design (how its built/works) → a form of cognitive psychology ai would fall under mind design, more about building things and making it work rather than analyzing what already exists psychology by reverse engineering is a materialist → the mind is nothing but matter in motion &amp;hellip; realize that things can be viewed from different perspectives (or described in different terms) –and, when we look differently, what we are able to see is also different” (p.</description></item><item><title>Symbolic Systems</title><link>https://jzhao.xyz/thoughts/symbolic-systems/</link><pubDate>Fri, 02 Jul 2021 15:05:25 -0400</pubDate><guid>https://jzhao.xyz/thoughts/symbolic-systems/</guid><description>Dreyfus Convergence of CS and Philosophy newell and simon claimed that both digital computers and the human mind could be understood as physical symbol systems using strings of bits or streams of neuron pulses as symbols representing the external world intelligence (as claimed by newell and simon) required making the appropriate inference from these internal representations &amp;ldquo;a physical symbol system has the necessary and sufficient means for general intelligent action&amp;rdquo; turning rationalist philosophy into a research program hobbes → reasoning was calculating descartes → mental representations leibniz → &amp;ldquo;universal characteristic&amp;rdquo; — a set of primitives in which all knowledge could be expresse kant → concepts are rules russell → logical atoms as the building blocks of reality Symbolic AI as a degenerating research program problem of representing significance and relevance → how do you transfer the learnings to the real world heidegger values are just meaningless facts (hammer is for hammering), leaves out information defining the relation of hammers to nails and the rest of the environment (readiness-to-hand) commonsense knowledge problem → how do we represent &amp;lsquo;common sense&amp;rsquo; in a way that is accessible to AI systems that use natural language problem isnt curating those facts, it&amp;rsquo;s knowing which facts are relevant in any given situations (the frame-problem ) should be able to ignore something without having to figure out that it should ignore it if the computer is running a representation of the current state of the world and something in the world chances, how does the program determine which of its represented facts can be assumed to have stayed the same, and which would have to be updated?</description></item><item><title>Embedded AI</title><link>https://jzhao.xyz/thoughts/embedded-ai/</link><pubDate>Fri, 02 Jul 2021 15:01:46 -0400</pubDate><guid>https://jzhao.xyz/thoughts/embedded-ai/</guid><description>Dreyfus Why Heideggerian AI failed and how fixing it would require making it more Heideggerian the frame approach → descriptions of typical situations like going to a birthday party however, this quickly grows out of hand once again as any AI program using frames to organize millions of meaningless facts so as to retrieve the relevant frames is going to be caught in a cycle of finding frames for recognizing relevant frames for recognizing relvant facts an emergent heideggerian cognitive science → embodied-embedded thinking is under active investigation and development john haugeland → cognition is embedded and embodied Three approaches to supposedly Heideggerian AI Rodney Brook&amp;rsquo;s behaviourist approach it turns out to be very difficult to reproduce in an internal representation for a computer the necessary richness of environment that would give rise to interesting behaviour by a highly adaptive robot this is avoided by human beings because their model of the world is the world itself &amp;ldquo;the best model of the world is the world itself&amp;rdquo; build a mobile robot that uses the world itself as its own representation (referring to its sensors rather than to an internal world model) problems does not learn operates in a fixed world, responding only to a small set of possibly relevant features that their receptors can pick up Phil Agre&amp;rsquo;s pragmatist model use of deictic representations instead of representing a particular object in the world represent a role that an object might play in a certain time-extended pattern of interaction between an agent and its environment objectified both functions and situational relevance for the agent e.</description></item><item><title>Machine Learning</title><link>https://jzhao.xyz/thoughts/machine-learning/</link><pubDate>Fri, 02 Jul 2021 14:03:17 -0400</pubDate><guid>https://jzhao.xyz/thoughts/machine-learning/</guid><description>Haugeland GOFAI (good old-fashioned AI) this view believes that the mind is a computer with certain special characteristics — namely the fact that its internal states and processes can be regarded as thinking or reasoning finding meaning in a body of symbols, like finding rationality in a body of behaviour, is finding a certain kind of consistent, reliable pattern problem solvers often use canny, methodical exploration neither algorithmic nor random a familiar sort of articulate reasoning or thinking a problem out &amp;ldquo;if only i could get that, then I could nail this down; but in order to get that, I would need such and such&amp;rdquo; GOFAI is very narrow-minded and vulnerable to unexpected variations and oddities in the problems and information they were given grounded in the possibility of translation — semantic interpretation NFAI (new-fangled AI) falls under connectionism and connectionist networks can retain memory short term → spiking neural networks, information within the system changes slowly long term → within connections themselves (weights and biases) adept at finding various sort of similarities among patterns, at recognizing repeated (or almost repeated) patterns and filling in missing parts of incomplete patterns NFAI learns from examples (but not in the same way humans do) connectionist mind design → relies on computers the same way a weather service does, to simulate digitally systems that are not in themselves digital inspired by the structure of the brain, but more deeply, by the importance and ubiquity of non-formal pattern reasoning very grab-bag term → anything that isn&amp;rsquo;t GOFAI argument that a lot of human intelligence is not embodied in anyone, its a part of the world e.</description></item><item><title>Semantics: What is Meaning?</title><link>https://jzhao.xyz/thoughts/semantics/</link><pubDate>Fri, 02 Jul 2021 13:49:27 -0400</pubDate><guid>https://jzhao.xyz/thoughts/semantics/</guid><description>Putnam meanings are public property → the same meaning be grasped by more than one person and by persons at different times Putnam&amp;rsquo;s argument my twin is thinking of XYZ and I am thinking of H2O XYZ ≠ H2O content determines object (frege: the sense of a term determines its referent) if t1 and t2 have different objects, then they must also have different content twin and I have thoughts with different content thoughts are individuated by their content twin and I h ave different thoughts even though we are molecule-for-molecule duplicates Implications if this argument is correct, then the content of our thoughts partly depends on what is in the world we live in (we can&amp;rsquo;t be BIVs) content determines object what about indexical thoughts?</description></item><item><title>Frame Problem</title><link>https://jzhao.xyz/thoughts/frame-problem/</link><pubDate>Fri, 02 Jul 2021 13:36:14 -0400</pubDate><guid>https://jzhao.xyz/thoughts/frame-problem/</guid><description>Dennet Frame problem of AI coined by McCarthy and Hayes → particular narrowly conceived problem about representation call the broader problem &amp;ldquo;the whole pudding&amp;rdquo; will refer to &amp;ldquo;the whole pudding&amp;rdquo; as the frame problem intelligence is (at least partly) a matter of using well what you know an intelligent being learns from experience, and then uses what is has learned to guide expectations in the futrue hume believed that we &amp;lsquo;think before we leap&amp;rsquo; because of associationism → certain transition paths between ideas grew more likely-to-be-followed as they became well worn dennet thinks this is flawed, hume operates at a purely semantic level (phenomenological level), one assumes that items behave as items with those meanings ought to behave hetero-phenomenologist → one reasons about what the agent must know or figure out either unconsciously or consciously in order to perform various tasks AI → is formulated tabula rasa (from scratch, no knowledge about the the world) everything either needs to be impressed by programmer at the outset subsequent learning by the system Installation problem problem of installing in one way or another all the information needed by an agent to plan in a changing world</description></item><item><title>Can Machines Think?</title><link>https://jzhao.xyz/thoughts/intelligence/</link><pubDate>Fri, 02 Jul 2021 13:29:33 -0400</pubDate><guid>https://jzhao.xyz/thoughts/intelligence/</guid><description>Intelligence as a measure of information conversation ratio. How do we test intelligence of machines vs humans?
Intelligence can only be contextually based on information available. There are no intrinsically difficult questions, only wrt inputs
Dretske Can intelligence be artificial? two ways of thinking about it like money → everyone has, some have more than others philosophers view like wealth → something possessed by only those who have more than the average amount of money computer scientists view thought alone is not enough, the thoughts need to do something, and sometimes explain the doing actions that are not governed by/explained by thought are not intelligent in order to be intelligent, the behaviour must be under the control of the content of the thought and not the vehicle of the content plant analogy even if you know what physical events inside the plant are causing the change in colour, don&amp;rsquo;t necessarily know why the plant is changing colour could be a result to encouraging different polinators or discouraging beetles from eating it what about laboratory grown?</description></item><item><title>Extended Mind</title><link>https://jzhao.xyz/thoughts/extended-mind/</link><pubDate>Fri, 02 Jul 2021 13:18:45 -0400</pubDate><guid>https://jzhao.xyz/thoughts/extended-mind/</guid><description>Sterelny Minds: extended or scaffolded?
Extended view of the mind not an internal control system, enclosed in the human body, receiving data from human sensory system and directing human action instead, as systems that extend far beyond the body of the human organism, systems that include extra-somatic resources: environmental fuels for adaptive action suggest that human cognitive systems include those resources that are importantly, robustly, reliably, or persistently supportive of decisions making Theory of Niche Construction many animals intervene in their environment, shaping it in ways that improve the adaptive fit between the agent and its world such animals in part adapt to their niche, in part construct their own the niche construction perspective focuses our attention on the common features of this whole range of cases whereas the extended mind model does not human capacities, cognitive and non-cognitive alike, turn out to depend on the fact that humans engineer their environment to support their activities extended digestion example some animals do the hard digestion stuff on-board, powerful jaws, large mouths, lots of time chewing we cook lmao also, we selectively breed livestock which improves the food value of domestic stock Extended Phenotypes Concept things animals build are part of their phenotype (physical exhibited traits that are determined genetically) developmentally stable, as heritable and predictable in their ecological effects as other traits e.</description></item><item><title>Emergent Behaviour</title><link>https://jzhao.xyz/thoughts/emergent-behaviour/</link><pubDate>Thu, 17 Jun 2021 00:21:11 -0400</pubDate><guid>https://jzhao.xyz/thoughts/emergent-behaviour/</guid><description>How complex behaviour can arise out of seemingly simple rules
Ant simulations Mold simulations Community dynamics Interesting to think about in context of single agents in multi-agent systems How does consciousness arise?
Even in systems of representation ,</description></item></channel></rss>